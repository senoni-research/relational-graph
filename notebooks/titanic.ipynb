{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LkE1JrLjFwhe"
   },
   "source": [
    "# KumoRFM vs. LightGBM on the Titanic dataset\n",
    "\n",
    "This notebook demonstrates single-table usage of `KumoRFM` and compares it to a strong tree-based baseline (`LightGBM`). We:\n",
    "- Load Titanic from `seaborn`\n",
    "- Create a single table with primary key `id`\n",
    "- Use a single, shared train/test split for both methods\n",
    "- Evaluate AUROC and compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: ensure seaborn is available in this kernel\n",
    "# %pip install -q seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1ries9szHZD3",
    "outputId": "e7aca011-7cd8-4ef4-e20e-9f4666e9336c"
   },
   "outputs": [],
   "source": [
    "# Optional: keep `kumoai` current in this environment\n",
    "# %pip install -q --pre --upgrade kumoai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1TD1bYpNHalN"
   },
   "outputs": [],
   "source": [
    "# Import the KumoRFM SDK\n",
    "from kumoai.experimental import rfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "KnSNyQVSHbjm",
    "outputId": "7ee5c915-bdea-48c6-af2b-31f2612a6fdf"
   },
   "outputs": [],
   "source": [
    "# Authentication: prefer env var `KUMO_API_KEY`; fall back to interactive auth\n",
    "import os\n",
    "\n",
    "if not os.environ.get(\"KUMO_API_KEY\"):\n",
    "    rfm.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Dh4VLlQHddD",
    "outputId": "1b5fc412-fb08-449f-de4c-1aef338bad0e"
   },
   "outputs": [],
   "source": [
    "# Initialize the SDK (prints deployment and logging level)\n",
    "rfm.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nM5zyWODF7xH",
    "outputId": "2b96dc37-e2ab-4e4a-a7bc-5cec61c56911"
   },
   "outputs": [],
   "source": [
    "# Load Titanic and create a single-table dataset\n",
    "# - Keep a simple set of numeric + categorical columns\n",
    "# - Create a single primary key `id`\n",
    "# - Create ONE shared stratified train/test split used by both KumoRFM and LightGBM\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load and pick a few useful columns\n",
    "df = sns.load_dataset(\"titanic\").copy()\n",
    "cols = [\"pclass\", \"sex\", \"age\", \"sibsp\", \"parch\", \"fare\", \"embarked\", \"alone\"]\n",
    "df = df[[\"survived\"] + cols].dropna(subset=[\"survived\"]).reset_index(drop=True)\n",
    "\n",
    "# Stable integer IDs\n",
    "df[\"id\"] = df.index\n",
    "\n",
    "# Shared train/test split (stratified)\n",
    "y = df[\"survived\"]\n",
    "train_ids, test_ids = train_test_split(\n",
    "    df[\"id\"].values, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# KumoRFM view: mask test labels to simulate missing-value imputation\n",
    "table = df[[\"id\"] + cols + [\"survived\"]].copy()\n",
    "table.loc[table[\"id\"].isin(test_ids), \"survived\"] = pd.NA\n",
    "\n",
    "display(table.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "bAL2IGYcGFxb",
    "outputId": "a3d891c9-c80b-4093-cc97-d1fe9a74f552"
   },
   "outputs": [],
   "source": [
    "# Build a local graph with a single table and instantiate KumoRFM\n",
    "from kumoai.experimental import rfm\n",
    "\n",
    "graph = rfm.LocalGraph.from_data({\"table\": table})\n",
    "model = rfm.KumoRFM(graph)\n",
    "\n",
    "graph[\"table\"].print_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test IDs using the KumoRFM query language\n",
    "id_list = \", \".join(str(i) for i in test_ids)\n",
    "query = f\"PREDICT table.survived=1 FOR table.id IN ({id_list})\"\n",
    "result = model.predict(query)\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDKjl9OAHT6S"
   },
   "source": [
    "Let's read this data frame into `KumoRFM`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248,
     "referenced_widgets": [
      "8a29ee474bb3497ea30913c03a945ed5",
      "513f3454458546a1a855009d9e52f225"
     ]
    },
    "id": "RDSlOfC7FVBx",
    "outputId": "d331621a-de52-439f-ba09-66f9d577e6ae"
   },
   "outputs": [],
   "source": [
    "# WARNING: This naive evaluation assumes result rows are ordered like `test_ids`.\n",
    "# In practice, always align by ID. The robust evaluation is in the next cell.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_test = df.set_index(\"id\").loc[list(test_ids), \"survived\"].to_numpy()\n",
    "prob_col = [c for c in result.columns if c.endswith(\"_PROB\")][0]\n",
    "y_pred = result[prob_col].to_numpy()\n",
    "print(f\"AUROC (naive): {roc_auc_score(y_test, y_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Robust evaluation: align predictions to ground-truth by ID, then compute AUROC\n",
    "# - KumoRFM returns an `ENTITY` column; we parse integer IDs from it\n",
    "# - We then gather `y_true` in exactly that row order\n",
    "# - Finally, choose the positive-class probability and compute AUROC\n",
    "import re\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Parse integer IDs from the ENTITY column\n",
    "def parse_entity_id(x):\n",
    "    if isinstance(x, (int, np.integer)):\n",
    "        return int(x)\n",
    "    m = re.search(r\"(\\d+)$\", str(x))\n",
    "    return int(m.group(1)) if m else None\n",
    "\n",
    "result_ids = result[\"ENTITY\"].map(parse_entity_id)\n",
    "assert result_ids.notna().all(), f\"Unparsed ENTITY values: {result['ENTITY'].head()}\"\n",
    "\n",
    "# Align y_true to the prediction rows\n",
    "y_true = df.set_index(\"id\").loc[result_ids, \"survived\"].to_numpy()\n",
    "\n",
    "# Pick positive-class probability\n",
    "prob_col = \"1_PROB\" if \"1_PROB\" in result.columns else (\"True_PROB\" if \"True_PROB\" in result.columns else result.filter(like=\"_PROB\").columns[0])\n",
    "y_pred = result[prob_col].to_numpy()\n",
    "\n",
    "auc = roc_auc_score(y_true, y_pred)\n",
    "auc_flip = roc_auc_score(y_true, 1 - y_pred)\n",
    "print(f\"AUC: {auc:.4f}  |  AUC(1-prob): {auc_flip:.4f}  |  prob_col: {prob_col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, classification_report, confusion_matrix\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "j = tpr - fpr\n",
    "best_idx = j.argmax()\n",
    "best_thresh = thresholds[best_idx]\n",
    "\n",
    "y_hat = (y_pred >= best_thresh).astype(int)\n",
    "print(\"Best threshold:\", best_thresh)\n",
    "print(classification_report(y_true, y_hat, digits=4))\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame({\"id\": result_ids, \"survived_true\": y_true, \"survived_prob\": y_pred, \"survived_pred\": y_hat})\n",
    "display(pred_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install LightGBM (one-time)\n",
    "# If already installed in the venv, this is a no-op\n",
    "%pip install -q lightgbm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM baseline using the SAME split and native categoricals\n",
    "# - Uses the same `train_ids`/`test_ids`\n",
    "# - Casts categorical columns to pandas `category` dtype\n",
    "# - Early stopping via callbacks (LightGBM v4+ sklearn API)\n",
    "import pandas as pd\n",
    "import logging\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "logging.getLogger(\"lightgbm\").setLevel(logging.ERROR)\n",
    "\n",
    "cat_cols = [\"sex\", \"embarked\", \"alone\", \"pclass\"]\n",
    "num_cols = [\"age\", \"sibsp\", \"parch\", \"fare\"]\n",
    "\n",
    "df_lgb = df[[\"id\", \"survived\"] + cat_cols + num_cols].copy()\n",
    "for c in cat_cols:\n",
    "    df_lgb[c] = df_lgb[c].astype(\"category\")\n",
    "\n",
    "train_mask = df_lgb[\"id\"].isin(train_ids)\n",
    "test_mask  = df_lgb[\"id\"].isin(test_ids)\n",
    "\n",
    "X_train = df_lgb.loc[train_mask, cat_cols + num_cols]\n",
    "y_train = df_lgb.loc[train_mask, \"survived\"].astype(int)\n",
    "X_test  = df_lgb.loc[test_mask,  cat_cols + num_cols]\n",
    "y_test  = df_lgb.loc[test_mask,  \"survived\"].astype(int)\n",
    "\n",
    "lgbm = LGBMClassifier(\n",
    "    n_estimators=1000,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    min_child_samples=10,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    reg_lambda=0.5,\n",
    "    random_state=42,\n",
    "    verbosity=-1,\n",
    ")\n",
    "\n",
    "lgbm.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_test, y_test)],\n",
    "    eval_metric=\"auc\",\n",
    "    categorical_feature=cat_cols,\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=100, verbose=False),\n",
    "        log_evaluation(period=0),\n",
    "    ],\n",
    ")\n",
    "\n",
    "y_pred_lgb = lgbm.predict_proba(X_test)[:, 1]\n",
    "auc_lgb = roc_auc_score(y_test, y_pred_lgb)\n",
    "print(\"LightGBM AUROC:\", auc_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare KumoRFM vs LightGBM on the SAME test split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc_kumo = roc_auc_score(y_true, y_pred)\n",
    "comparison = pd.DataFrame({\"Model\": [\"KumoRFM\", \"LightGBM\"], \"AUROC\": [auc_kumo, auc_lgb]}).sort_values(\"AUROC\", ascending=False)\n",
    "display(comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "513f3454458546a1a855009d9e52f225": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8a29ee474bb3497ea30913c03a945ed5": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_513f3454458546a1a855009d9e52f225",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅</span> <span style=\"color: #008000; text-decoration-color: #008000\">Materializing graph (0.00s)                 </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Sanitized input data                      </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Collected primary key from 1 table        </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Identified static graph without timestamps</span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Created graph with 569 nodes and 0 edges  </span>\n</pre>\n",
         "text/plain": "\u001b[32m✅\u001b[0m \u001b[32mMaterializing graph (0.00s)                 \u001b[0m\n   \u001b[2m↳ Sanitized input data                      \u001b[0m\n   \u001b[2m↳ Collected primary key from 1 table        \u001b[0m\n   \u001b[2m↳ Identified static graph without timestamps\u001b[0m\n   \u001b[2m↳ Created graph with 569 nodes and 0 edges  \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    },
    "b7bf1eafc9914c1da240bfdb2caedbc1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "faa2e6434ee4495a869aa3c268676665": {
     "model_module": "@jupyter-widgets/output",
     "model_module_version": "1.0.0",
     "model_name": "OutputModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/output",
      "_model_module_version": "1.0.0",
      "_model_name": "OutputModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/output",
      "_view_module_version": "1.0.0",
      "_view_name": "OutputView",
      "layout": "IPY_MODEL_b7bf1eafc9914c1da240bfdb2caedbc1",
      "msg_id": "",
      "outputs": [
       {
        "data": {
         "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">✅</span> <span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">PREDICT</span><span style=\"color: #008000; text-decoration-color: #008000\"> table.target=1 </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">FOR</span><span style=\"color: #008000; text-decoration-color: #008000\"> table.id </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">IN</span><span style=\"color: #008000; text-decoration-color: #008000\"> (0, 1, 2, 3, 4, ...) (0.65s)</span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Identified static binary classification task                     </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Collected 284 in-context examples with 59.86% positive cases     </span>\n   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">↳ Generated context of size 0.10MB                                 </span>\n</pre>\n",
         "text/plain": "\u001b[32m✅\u001b[0m \u001b[1;32mPREDICT\u001b[0m\u001b[32m table.target=1 \u001b[0m\u001b[1;32mFOR\u001b[0m\u001b[32m table.id \u001b[0m\u001b[1;32mIN\u001b[0m\u001b[32m (0, 1, 2, 3, 4, ...) (0.65s)\u001b[0m\n   \u001b[2m↳ Identified static binary classification task                     \u001b[0m\n   \u001b[2m↳ Collected 284 in-context examples with 59.86% positive cases     \u001b[0m\n   \u001b[2m↳ Generated context of size 0.10MB                                 \u001b[0m\n"
        },
        "metadata": {},
        "output_type": "display_data"
       }
      ]
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
